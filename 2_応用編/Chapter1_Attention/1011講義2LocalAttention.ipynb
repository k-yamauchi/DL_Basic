{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Attention\n",
    "\n",
    "## Attentionとは\n",
    "連続したデータを扱う際に過去の重要なポイントに着目する(=Attention)ための手法\n",
    "\n",
    "最終時刻の結果しか用いないより全部使った方がいい\n",
    "\n",
    "実際LSTMも最終時刻だけより、全時刻の平均を用いる方が少し良いらしい\n",
    "\n",
    "## Attentionを行う流れ\n",
    "\n",
    "- これまでの隠れ層に対し、何らかの形でスコアリングする\n",
    "- スコアをsoftmax関数にかけて正規化する\n",
    "- 得られた重みについてそれぞれの隠れ層を加重平均する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Machine Translation + Attention\n",
    "\n",
    "### Global Attention Model\n",
    "<img src='img/encdecattention.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$ a_t = \\frac{score(h_t,\\bar{h_s})}{\\sum_{s'}{score(h_t,\\bar{h_s'}})}$$\n",
    "\n",
    "<img src ='img/score.png' width=300>\n",
    "\n",
    "### $$ c_t = \\sum_s \\alpha_t(s)\\bar{h_s} $$\n",
    "\n",
    "### $$ \\tilde{h_t} = tanh{W_c[c_t;h_t]} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Attention\n",
    "論文：[Effective Approaches to Attention-based Neural Machine Translation](http://aclweb.org/anthology/D15-1166)\n",
    "<img src ='img/localattention.png' width =600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれの単語についてscoreを計算しなくてもよくない？\n",
    "\n",
    "Globalは長い文になると計算コスト増える\n",
    "\n",
    "Local Attentionは更に見る場所を限定する  [$p_t-D,p_t+D$]\n",
    "\n",
    "\n",
    "### 1. $p_t$の計算 \n",
    "<img src ='img/p_t.png' width =300>\n",
    "$p_t$は[0,S]の値を取り、どこの単語を中心に見たらいいかを判断する\n",
    "\n",
    "\n",
    "### 2.scoreの計算\n",
    "\n",
    "Global Attentionの時と同様だが、$p_t$から前後D個のみ計算\n",
    "\n",
    "つまり$2D+1$個のAttentionを計算\n",
    "\n",
    "<img src ='img/localattention3.png' width=400>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.　正規分布を仮定\n",
    "<img src ='img/seikibunpu2.png' width =400>\n",
    "\n",
    "defaultでは$\\sigma=\\frac{D}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. scoreの再計算\n",
    "\n",
    "<img src ='img/scorerecalc.png' width =400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.以下同様...\n",
    "\n",
    "\n",
    "### $$ c_t = \\sum_s \\alpha_t(s)\\bar{h_s} $$\n",
    "\n",
    "### $$ \\tilde{h_t} = tanh({W_c[c_t;h_t]}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
