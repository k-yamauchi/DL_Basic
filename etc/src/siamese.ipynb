{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding,Input,Reshape,Subtract,Conv2D,MaxPool2D,Concatenate,Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 5,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 5,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading embeddings vectors\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    "pretrained_model = 'data/glove.6B.50d.txt'\n",
=======
    "pretrained_model = '../data/glove.6B.50d.txt'\n",
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
    "pretrained_model = '../data/glove.6B.50d.txt'\n",
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
    "pretrained_model = '../data/glove.6B.50d.txt'\n",
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
    "print('loading embeddings vectors')\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(' ')) for o in open(pretrained_model))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 21,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 21,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 21,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "# HyperParams# HyperP \n",
    "max_features = 20000   #学習に用いる単語数\n",
    "maxlen = 80  #学習に用いる最大長(これ以上は省略する)\n",
    "batch_size = 32\n",
    "embed_size = 50  #単語埋め込み次元数(今回は学習済みが50次元なので50次元)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 17,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 17,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 17,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeroPadding"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 18,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 18,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 18,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrixの作成"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 19,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 19,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 19,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "INDEX_FROM=3   \n",
    "\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 20,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 20,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 20,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create embedding matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
     "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
     "execution_count": 25,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('create embedding matrix')\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "\n",
    "for word, i in word_to_id.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese networkの構造\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1200/1*XzVUiq-3lYFtZEW3XfmKqg.jpeg' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文書のEncoder部分"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 26,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 26,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 26,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "out_size=16\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 32"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 75,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 75,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 75,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "def make_encoder():\n",
    "    inputs =Input(shape=(maxlen,))\n",
    "    emb= Embedding(max_features, embed_size, weights=[embedding_matrix],trainable=False)(inputs)  #Embedding層\n",
    "    reshape = Reshape((maxlen,embed_size,1))(emb)\n",
    "\n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "    concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "    flatten = Flatten()(concatenated_tensor)\n",
    "\n",
    "    out = Dense(out_size, activation='linear')(flatten)\n",
    " \n",
    "    encoder = Model(inputs, out)\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手法１ 通常のtextCNN"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 90,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 90,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 90,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 16)                1020848   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "input_29 (InputLayer)        (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "model_19 (Model)             (None, 16)                1020848   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 17        \n",
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "=================================================================\n",
      "Total params: 1,020,865\n",
      "Trainable params: 20,865\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = make_encoder()\n",
    "\n",
    "inp = Input((maxlen,))\n",
    "enc = encoder(inp)\n",
    "out = Dense(1,activation='sigmoid')(enc)\n",
    "model = Model(inp,out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 91,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 91,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 91,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 95,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 95,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 95,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "25000/25000 [==============================] - 15s 608us/step - loss: 0.5233 - acc: 0.7321 - val_loss: 0.4614 - val_acc: 0.7789\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 15s 602us/step - loss: 0.4087 - acc: 0.8125 - val_loss: 0.4280 - val_acc: 0.7987\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 15s 600us/step - loss: 0.3608 - acc: 0.8381 - val_loss: 0.4292 - val_acc: 0.8015\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 15s 595us/step - loss: 0.3091 - acc: 0.8677 - val_loss: 0.4423 - val_acc: 0.8010\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 15s 596us/step - loss: 0.2731 - acc: 0.8845 - val_loss: 0.4686 - val_acc: 0.7984\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 15s 598us/step - loss: 0.2364 - acc: 0.9014 - val_loss: 0.5488 - val_acc: 0.7807\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 15s 600us/step - loss: 0.1987 - acc: 0.9199 - val_loss: 0.5852 - val_acc: 0.7877\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 15s 600us/step - loss: 0.1757 - acc: 0.9294 - val_loss: 0.6102 - val_acc: 0.7896\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 15s 602us/step - loss: 0.1387 - acc: 0.9468 - val_loss: 0.9703 - val_acc: 0.7335\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 15s 607us/step - loss: 0.1220 - acc: 0.9527 - val_loss: 0.7839 - val_acc: 0.7777\n"
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "25000/25000 [==============================] - 9s 365us/step - loss: 0.5207 - acc: 0.7336 - val_loss: 0.4448 - val_acc: 0.7882\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 8s 336us/step - loss: 0.4095 - acc: 0.8126 - val_loss: 0.4256 - val_acc: 0.8010\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.3622 - acc: 0.8392 - val_loss: 0.4387 - val_acc: 0.7966\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.3191 - acc: 0.8607 - val_loss: 0.4411 - val_acc: 0.8014\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.2863 - acc: 0.8789 - val_loss: 0.4561 - val_acc: 0.8020\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.2388 - acc: 0.9005 - val_loss: 0.5106 - val_acc: 0.7906\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 8s 336us/step - loss: 0.2058 - acc: 0.9186 - val_loss: 0.5612 - val_acc: 0.7878\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 8s 334us/step - loss: 0.1886 - acc: 0.9250 - val_loss: 0.6263 - val_acc: 0.7784\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.1509 - acc: 0.9437 - val_loss: 0.6501 - val_acc: 0.7863\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 8s 335us/step - loss: 0.1361 - acc: 0.9473 - val_loss: 0.7578 - val_acc: 0.7750\n"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
       "<keras.callbacks.History at 0x1105d3ef0>"
      ]
     },
     "execution_count": 17,
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
       "<keras.callbacks.History at 0x7f19706b39b0>"
      ]
     },
     "execution_count": 95,
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siameseネットワークの構築"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 97,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 97,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 97,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(maxlen,))\n",
    "inp2 = Input(shape=(maxlen,))\n",
    "\n",
    "encoder1 = make_encoder()\n",
    "encoder2 = make_encoder()\n",
    "\n",
    "out1 = encoder1(inp1)\n",
    "out2 = encoder2(inp2)\n",
    "\n",
    "x =Concatenate()([out1,out2])\n",
    "\n",
    "pred = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model([inp1,inp2],pred)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 98,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 98,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 98,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 99,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 99,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 99,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "input_3 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 16)           1020848     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 16)           1020848     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32)           0           model_3[1][0]                    \n",
      "                                                                 model_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          concatenate_4[0][0]              \n",
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "input_34 (InputLayer)           (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_24 (Model)                (None, 16)           1020848     input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_25 (Model)                (None, 16)           1020848     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 32)           0           model_24[1][0]                   \n",
      "                                                                 model_25[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            33          concatenate_21[0][0]             \n",
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "==================================================================================================\n",
      "Total params: 2,041,729\n",
      "Trainable params: 41,729\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 100,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 100,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 100,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train groups: [12500, 12500]\n",
      "test groups: [12500, 12500]\n"
     ]
    }
   ],
   "source": [
    "# reorganize by groups\n",
    "train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)]\n",
    "test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)]\n",
    "print('train groups:', [x.shape[0] for x in train_groups])\n",
    "print('test groups:', [x.shape[0] for x in test_groups])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 101,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 101,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 101,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
    "    out_img_a, out_img_b, out_score = [], [], []\n",
    "    all_groups = list(range(len(in_groups)))\n",
    "    for match_group in [True, False]:\n",
    "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
    "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
    "        if match_group:\n",
    "            b_group_idx = group_idx\n",
    "            out_score += [1]*batch_halfsize\n",
    "        else:\n",
    "            # anything but the same group\n",
    "            non_group_idx = [np.random.choice([i for i in all_groups if i!=c_idx]) for c_idx in group_idx] \n",
    "            b_group_idx = non_group_idx\n",
    "            out_score += [0]*batch_halfsize\n",
    "            \n",
    "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
    "            \n",
    "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 102,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 102,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 102,
   "metadata": {},
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "outputs": [],
   "source": [
    "pv_a, pv_b, pv_sim = gen_random_batch(train_groups, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチの確認"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 103,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 103,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 103,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "元文章1 line are just stupid of course he is the dominating one while his weak white roommates sit in fear of him and eventually move out this movie was just terrible and the ending made me actually laugh out loud the overly long slow motion between epps and banks gets hilarious with the faces they make it's like watching my nephew and cousins making faces at each other and they're all under 5 do yourself a favor and skip this crapfest\n",
      "元文章2 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> and that's why hard to rate br br from the adult point of view hmm student point of view i must say i fell nearly asleep here sure there is some laughing scene all the credit takes here eddie but that can't save the disney type of script and whole movie that's why br br 2 out of 10\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 a spectacular show down between the witches at the end of the movie with at least some special effects flaming eyes or whatever but nothing happens there is sort of a confrontation in the end but it's a big disappointment br br so the acting of the two witches was good the musical score was decent even though overly ambitious and the cinematography was rather dark and moody at times but that doesn't make a good movie yet does it\n",
      "元文章2 sun detective story streetcar named desire abbott and costello meet the invisible man you name it if it came out in <UNK> it's better than this arthouse <UNK> the closing ballet is claptrap for the intellectual crowd out of place and in the wrong movie few actors in their time were less capable at acting or less charismatic than kelly and caron my 12 worst of <UNK> i saw <UNK> movies and among the 5 worst best picture oscar winners\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 of art that need to be appreciated more br br the idea that it was nominated for 11 oscars even best picture of the year and didn't get one trophy is a sign of how blind and stupid hollywood can be sometimes spielberg wasn't even nominated for best director it should have swept the oscars that year br br the film clearly shows you how unfair life is for some people br br if only movies were still this good\n",
      "元文章2 that i didn't see and i what to see it so badly like part two it showed an appearance of torch which can turn things and humans which is cool and showed the return of the puppet master from part one it also showed little aliens from part 4 that was also cool it showed other people episodes that might be good to them and it did so thanks to this puppet master is going to be a big hit\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 a prison work gang to go on a secret mission to se asia to free some american <UNK> in a running battle he kills about 500 enemy soldiers with an m 60 machine gun that never runs out of ammo and never <UNK> and he never misses running with a <UNK> gun held up with one arm i could go on but i'm getting a headache i gave this a 2 10 only because it's slightly better than rambo iii\n",
      "元文章2 br the film is shot in a tongue in cheek let it all hang out manner with music appropriately <UNK> this technique home it's about the ultra violence simple as that with some deranged behavior and jet black humor <UNK> <UNK> direction and king's screenplay the incestuous angle of the sleepwalkers is a bit jarring and in your face without a lick of complexity this is closer in vein to king's own demented <UNK> overdrive than his more serious works\n",
      "類似度 0\n",
      "-----------------------------\n",
      "元文章1 characters are real the situations are believable and it doesn't shy away from the darker side of life confronted every day by cops and the criminals victims lawyers and other people in their various <UNK> br br this show ran for 2 seasons and was <UNK> because the show didn't sell well overseas we are all sorry for its loss however like fawlty towers we will be able to <UNK> this as a limited length series of uniformly high quality\n",
      "元文章2 bits of humor and warmth to a dark and serious film i also thought the film had a great look to it all shadows and fog very film noir in feel br br even though the actors do the best they can and the directing is enjoyable it still just isn't enough for me to recommend spending the time to view the film there are far better glenn ford movies out there the big heat <UNK> affair in <UNK> etc\n",
      "類似度 0\n",
      "-----------------------------\n",
      "元文章1 to i do believe that sabu had to have influenced the director's of <UNK> stock two smoking <UNK> and <UNK> lola <UNK> but i absolutely loved the way the three leads see the beautiful woman on the street to distract them momentarily i really need to see this director's other work because this film really intrigued me if you want insight culture <UNK> <UNK> <UNK> go somewhere else if you want a laugh camera movement and criminal hilarity look here\n",
      "元文章2 br br guy ritchie who has built his reputation on lock stock could never direct either his movies are shallow badly cut fashion shows he doesn't disappoint here either he wisely cast his wife as the star of this debacle br br please people take little heed of the good reviews this movie has received from other posters below they are quite obviously business plants br br don't encourage ritchie to humiliate himself further by giving him money br br\n",
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "元文章1 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> it is so rare that i get to rate a movie without having some reservation as to whether i should have gone up one or down one but this one did the explosion rate a notch higher or one down because my brain hurt trying to create a plot no this one yeah a solid no brainer one ten\n",
      "元文章2 the acting is below par it features a lot of really annoying rap music and poorly edited fight scenes on the plus side it's got that hispanic bloke in it who stars in every prison action thriller ever made and he shuts a door in this br br it's not very <UNK> but at least it's harmless br br if you were a massive fan of the original it's okay ish stuff br br if not you have been warned\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 revenge on the <UNK> kids who wronged him plot will of course be familiar to those who've watched it before and those who've seen it before will probably watch it again those who are expecting ingmar bergman and will subsequently become <UNK> about their wasted time should just skip it marilyn manson on the soundtrack and david boreanaz denise richards and katherine <UNK> as eye candy go with the flow and enjoy it oh and i loved the creepy mask\n",
      "元文章2 the idea if anything <UNK> to the diversity and range of african themes with his film 500 years later it is a african issue but the idea doesn't fit that mold showing the artistic diversity the film is an all african cast but the topic is a human topic which most of us could relate to i just love the mild comedy in it and the <UNK> of <UNK> <UNK> is just amazing it is really a art house gem\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 thanks to fine performances tight direction by john sturges the crisp monochrome cinematography of victor <UNK> and an atmospheric score by dimitri <UNK> extras however are no great shakes except for a radio version of jeopardy and trailers for both movies br br this disc is also part of a barbara stanwyck box set celebrating her <UNK> hard to believe that the lady would be over 100 years old if she was still around br br jeopardy an mgm winner\n",
      "元文章2 devastated br br improvisation might still be there though among all these wonderful performances near the end there's an unexpected scene where cassavetes and rowlands start talking non stop whether this was improvised or not is not something we have to wonder we have just got to watch and watching both of them exchanging life experiences and seeing words come truly alive in a conversation that means a lot more than what it <UNK> doesn't get more natural than that\n",
      "類似度 1\n",
      "-----------------------------\n",
      "元文章1 exquisite even the shabby ones br br the two young lads who play oliver and the artful dodger are wonderfully talented oliver reed does a great job portraying bill sykes to where you can't help but hope he comes to a terrible end which he does br br the dancing is cleverly choreographed and is mesmerizing oliver can hold its own with the likes of my fair lady the sound of music oklahoma etc a film for the entire family\n",
      "元文章2 bad but down right horrible and of no redeeming quality the plot was there one seemed to go no where the russians played silly kill or be killed games and the rest of the cast should be declared <UNK> and void for their pathetic performances i gave up about 3 4 of the way through and turned it off a 1 for awful only because there is nothing lower don't waste your time on this one you'll not miss anything\n",
      "類似度 0\n",
      "-----------------------------\n",
      "元文章1 eastwood or john wayne and more a three dimensional <UNK> his relationship with brennan is well played understated but nevertheless touching with a faint suggestion of george and lenny from of mice and men an altogether different type of western br br i certainly have more westerns to see but this is for now my favorite and the <UNK> by which i will necessarily judge all the others it deserves to be much better known and appreciated than it is\n",
      "元文章2 football teammates that he got diane pregnant in no way shape or form would a guy ever cheer another guy getting a girl pregnant in high school they might cheer about the guy having sex with the hot cheerleader but i can also guarantee that the first the football team heard about it would not be at a <UNK> br br it was obvious that this film didn't take itself so seriously and it wasn't hideously bad but come on\n",
      "類似度 0\n",
      "-----------------------------\n",
      "元文章1 it's packaged along with 1970's movies as metamorphosis is part of mill creek <UNK> 50 chilling classics there is basically no film quality difference whatsoever the final five minutes are pure bad movie cheese that actually for me at least save the movie from a lower rating pay attention to the computer terminology such as <UNK> <UNK> no wonder peter's experiment failed your computer can't spell this is worthy of a view followed by a trip to your local tavern\n",
      "元文章2 is pretty good movie robert culp was very good in the movie and was perfect for the part its hard to believe that this is a true story but what can you do when i watched this i thought why do they have to do all of those things it isn't right but they learned their lesson when they picked on the wrong man anyway if you ever see this movie on tv watch it because its a good one\n",
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "類似度 0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for line1,line2,sim in zip(pv_a,pv_b,pv_sim):\n",
    "    print('元文章1',' '.join(id_to_word[id] for id in line1))\n",
    "    print('元文章2',' '.join(id_to_word[id] for id in line2))\n",
    "    print('類似度',sim)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 104,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 104,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "execution_count": 104,
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
      "  3/500 [..............................] - ETA: 2:04 - loss: 0.7464 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.138122). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.120148). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/500 [..............................] - ETA: 1:38 - loss: 0.7357 - acc: 0.4740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.117505). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114862). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107752). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/500 [..............................] - ETA: 1:21 - loss: 0.7289 - acc: 0.4744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.111967). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106304). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 54s 107ms/step - loss: 0.7027 - acc: 0.4973 - val_loss: 0.6987 - val_acc: 0.4995 0.7082 - a - ETA: 51s - loss: 0.7113 - acc - ETA: 50s - loss: 0.7104 - - ETA: 49s - loss: 0.7106 - acc:  - ETA: 48s - loss: 0. - ETA: 47s - loss: 0.7104 - acc:  - ETA: 46s - loss: 0.7102 - acc:  - ETA: 46s - loss: 0.7102 - acc: 0.49 - ETA: 46s - loss: 0.7106 - - ETA: 45s -  - ETA: 40s - loss: 0.7075 - acc: 0. - ETA: 40s - loss: 0.70 - ETA: 39s - loss: 0.7069 - acc: 0.50 - ETA: 39s - loss: 0.7072 - acc: 0. - ETA: 39s - loss: 0.7068 - acc - ETA: 38s - loss - ETA: 37s - loss: 0.7067 - acc:  - ETA: 37s - loss: 0.7065 - ETA: 36s - loss: 0.7055 - acc: 0. - ETA: 35s - loss: 0.7054 - a - ETA: 35s -  - ETA: 33s - loss: 0.7055 - acc: 0.50 - ETA: 33s - loss:  - ETA: 32s - loss: 0.7052 - a - ETA: 32s - loss: 0.7048 - - ETA: 31s - loss: 0.7045 - acc:  - ETA: 31s - loss:  - ETA: 29s - loss: 0.7042 - ETA: 29s - loss: 0.7040 - acc: 0.50 - ETA: 29s - loss: 0.7042 - - ETA: 28s - loss: 0.7041 - acc: 0.50 - ETA: 28s - loss: 0.7041 - - ETA: 27s - loss: 0.7041 - acc:  - ETA: 27s - loss: 0.7038 - acc: 0.50 - ETA: 27s - loss: 0.7038 - acc:  - ETA: 26 - ETA: 25s - loss: 0. - ETA: 24s - loss: 0.7032 - acc: 0.50 - ETA: 24s - loss: 0.7031 - acc - ETA: 23s - loss: 0.7028 - acc: 0.50 - ETA: 23s - loss: 0.7029 - acc: 0. - ETA: 23s - loss: 0.7030 - acc: 0.50 - ETA: 23s - loss: 0.7030 - acc: 0.50 - ETA: 23s - loss: 0.7030 - acc: 0. - ETA: 22s  - ETA: 21s - loss: 0.7034 - acc - ETA: 21s - loss: 0.7035 - acc - ETA: 20s - lo - ETA: 17s - loss: 0.70 - ETA: 16s - loss: 0.7035 - a - ETA: 15s - loss: 0.7034 - acc: 0.49 - ETA: 15s - loss: 0.7034 - acc: 0. - ETA: 15s - loss: 0.7034 - acc: 0.49 - ETA: 15s - loss: 0.7034 - acc: 0. - ETA: 15s - loss: 0.7033 - acc: 0. - ETA: 14s - loss: 0.7033 - acc:  - ETA: 14s - lo - ETA: 13s - loss: 0.7032 - acc: 0.49 - ETA: 13s - loss: 0.7031 - acc - ETA: 12s - loss: 0.7031 - acc: 0. - ETA: 12s - loss: 0.7031   - ETA: 5s - loss: 0.7028 - acc: 0.496 - ETA: 5s - loss: 0.7028 - acc - ETA: 4s - loss: 0.7027 - acc: 0.4 - ETA: 4s - loss: 0.7027  - ETA: 3s - loss: 0.7025 - acc: 0 - ETA: 2s - loss: 0.7025 - acc: 0.499 - ETA: 2s - loss: 0.7025 - acc: 0.4 - ETA: 2s - loss: 0.7025 - acc: 0.498 - ETA: 2s - loss: 0.7026 - acc: 0.4 - ETA: 1s - loss: 0.70\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.6965 - acc: 0.4996 - val_loss: 0.6993 - val_acc: 0.49767s - loss: 0.6971 - a - ETA: 49s - loss: 0.7000 - acc: 0. - ETA: 49s - loss: 0.6973 - acc:  - ETA: 49s - loss: 0.6975 - acc:  - ETA: 49s - lo - ETA: 48s - loss: 0.6991 - acc:  - ETA: 46s - lo - ETA: 44s  - ETA: 42s - loss: 0.6986 - acc: 0. - ETA: 42s - loss: 0.6989 - acc - ETA: 41s - loss: 0.6987 - acc:  - ETA: 41s - lo - ETA: 40s - loss: 0. - ETA: 39s - loss:  - ETA: 38s - loss: 0.6984 - acc - ETA: 38s - loss: 0.6982 - - ETA: 37s - loss: 0.69 - ETA - ETA: 32s - loss: 0.6974 - acc:  - ETA: 32s - loss: 0. - ETA: 31s - loss: 0.6972 - acc:  - ETA: 30s - loss: 0.6976 - a - ETA: 30s - loss: 0. - ETA: 29s - loss: 0.6974 - acc: 0. - ETA: 29s - loss: 0.6973 - acc: 0.49 - ETA: 28s - loss: 0.69 - ETA: 28s - loss:  - ETA: 26s - loss: 0. - ETA: 25s - loss: 0.6971 - - ETA: 23s - loss: 0.6970 - acc:  - ETA: 22s - loss:  - ETA: 17s - loss: 0.6972 - a - ETA: 16s - loss - ETA: 15s - loss: 0.6975 - acc - - ETA: 11s - loss: 0.6972 - - ETA: 10s - loss: - ETA: 8s - loss: 0.6969 - acc: 0.4 - ETA: 8s - loss: 0.6969 - acc: 0.496 - ETA: 8s - loss: 0.6969 - ETA: 7s - loss: 0.6967 - acc: 0.4 - ETA: 6s - loss: 0.6966 - acc - ETA: 5s - loss: 0 - ETA: 3s - loss: 0.6965 - acc: 0 - ETA: 3s -  - ETA: 0s - loss: 0.6965 - acc: 0.4 - ETA: 0s - loss: 0.6965 - acc: 0.499 - ETA: 0s - loss: 0.6965 - acc: 0.499\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.6962 - acc: 0.5008 - val_loss: 0.6967 - val_acc: 0.4893- acc: 0.49 - ETA: 48s - loss: 0.6952 - acc: 0. - ETA: 47s  - ETA: 46s - loss: 0.6966 - acc: 0. - ETA:  - ETA: 44s - loss: 0.6940 - - ETA: 44s - loss: 0.6944 - acc: 0.51 - ETA: 44s - loss: 0.69 - ETA: 43s - loss:  - ETA: 42s - loss: 0.6953 - a - ETA: 41s - loss: 0.6957 - - ETA: 41s - loss: 0.6956 - a - ETA: 40s - loss: 0.6959 - acc:  - E - ETA: 38s - loss: 0.6960 - a - ETA: 38s - loss - ETA: 24s - loss: 0.6958 - acc: 0. - ETA: 24s - lo - ETA: 23s - loss: 0.6955 - a - ETA: 22s - loss: 0.6955 - acc:  - ETA: 22s - loss: 0.6953 - acc - ETA: 21s - loss:  - ETA: 20s - lo - ETA: 19s - loss: 0.69 - ETA: 18s - loss: 0.6957 - acc: 0. - ETA: 18s - loss: 0.6956 - acc: 0.50 - ETA: 18s - loss: 0.6957 - acc: 0.50 - ETA: 18s - loss: 0.6957 - acc: 0. - ETA - ETA: 14s - loss: 0.69 - ETA: 11s - loss: 0. - ETA: 10s - loss: 0.6960 - acc:  - ETA: 9s - loss: 0 - ETA: 7s - loss: 0.6960 - acc: 0.504 - ETA: 7s - loss: 0.6960 - a - ETA: 6s - loss: 0.6960 - acc: 0.504 -  - ETA: 2s - loss: 0.6960 - acc: - ETA: 1s - loss: 0.6960 - a - ETA: 0s - loss: 0.6961 - acc: 0. - ETA: 0s - loss: 0.6962 - acc: 0.501 - ETA: 0s - loss: 0.6962 - acc: 0.50\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.6952 - acc: 0.5019 - val_loss: 0.6960 - val_acc: 0.5063s: 0.6989 - acc: 0. - ETA: 47s - loss: 0.6989 - a - ETA: 46s - loss: 0.69 - E - ETA: 43s - loss: 0.6950 - a - ETA: 43s - loss: 0.6954 - acc: 0. - ETA: 43s - loss: 0.6955 - acc - ETA: 42s - loss: 0.6955 - - ETA: 42s - loss: 0.6952 - acc - ETA: 41s - loss: 0.6951 - ETA: 40s - loss: 0.6950 - ETA: 40s - loss: 0.69 - ETA: 37s - loss: 0.6950 - acc: 0. - ETA: 37s - loss: 0.6952 - acc: 0. - ETA: 36s -  - ETA: 33s - loss: 0.6952 - a - ETA: 32s - loss: 0.6950 - acc:  - ETA: 32s - lo - ETA: 27s - loss: 0.6951 - a - E - ETA: 18s - loss: 0. - ETA: 17s - loss: 0. - ETA: 14s - lo - E - ETA: 11s - loss: 0.69 - ETA: 10s - loss: 0.6954 - acc:  - ETA: 9s - loss: 0.6954 - acc: 0.5 - ETA: 9s - loss: 0.6954 - - ETA: 8s - loss: 0.6953 - acc: 0 - ETA: 7s - loss: 0.695 - ETA: 6s - loss: 0.6952 - acc: 0.5 - ETA: 5s - loss: 0.6951 - acc: 0 - ETA: 5s - loss: 0.6952 - acc: 0. - ETA: 4s - loss: 0.6952 - acc: 0.501 - ETA: 4s - loss: 0.6952 - acc: 0.50 - ETA: 4s - loss: 0.6951 - acc: 0.5 - ETA: 4s - loss: 0.6951 - acc: 0. - ETA: 3s - loss: 0.6952 - acc: 0. - ETA: 3s - loss: 0.695 - ETA: 1s - loss: 0.6951\n",
      "Epoch 5/10\n",
      "300/500 [=================>............] - ETA: 2:10:35 - loss: 0.6953 - acc: 0.5058 - ETA: 23:39:21 - lo - ET - ETA: 7:48:52 - loss:  - ETA: 6:56:20 - loss: 0.6961 - acc:  - ETA: 6:42:22 - loss: 0.6960 - a - ETA: 6:20:37 - loss: 0.6960 - a - ETA: 6:00:37 - loss: 0.6962 - acc: 0. - E - ETA: 6:12:2 - ETA: 5:25:52 - loss - ETA: 4: - E - ETA: 2:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.189673). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/500 [=================>............] - ETA: 2:08:26 - loss: 0.6953 - acc: 0.5064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.164308). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.143315). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/500 [=================>............] - ETA: 2:06:18 - loss: 0.6953 - acc: 0.5066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.134740). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.119812). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/500 [=================>............] - ETA: 2:04:12 - loss: 0.6953 - acc: 0.5065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.107798). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102509). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 18978s 38s/step - loss: 0.6954 - acc: 0.5020 - val_loss: 0.6961 - val_acc: 0.4829 - E - E - ETA: 46:35 - loss: 0. - ETA: 41:18 - loss: 0.6955 - acc: 0. - E - E - E\n",
      "Epoch 6/10\n",
      " 39/500 [=>............................] - ETA: 11:49:59 - loss: 0.6958 - acc: 0.4912 41s - loss: 0.6978 - acc - ETA: 46s - loss: 0.6984 - - ETA - ETA: 47s - loss: 0.6968 - ac - ETA: 1:15 - loss: 0.6958 - acc: 0.48"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.141722). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/500 [=>............................] - ETA: 10:38:27 - loss: 0.6956 - acc: 0.4920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101891). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/500 [=====>........................] - ETA: 3:22:10 - loss: 0.6959 - acc: 0.4859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.200247). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "116/500 [=====>........................] - ETA: 3:19:55 - loss: 0.6960 - acc: 0.4860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.179723). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.167858). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/500 [======>.......................] - ETA: 3:17:42 - loss: 0.6961 - acc: 0.48 - ETA: 3:15:32 - loss: 0.6961 - acc: 0.4849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.165904). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.151687). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/500 [======>.......................] - ETA: 3:11:17 - loss: 0.6961 - acc: 0.4859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.129873). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.129043). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/500 [======>.......................] - ETA: 3:07:10 - loss: 0.6961 - acc: 0.4859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.117437). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.112118). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/500 [======>.......................] - ETA: 2:57:27 - loss: 0.6962 - acc: 0.4872 ETA: 3:03:12 - loss: 0.6962 - acc: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109986). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100062). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/500 [===================>..........] - ETA: 1:41:15 - loss: 0.6958 - acc: 0.4966 ETA: 2:23:48 - loss: 0.6957 - acc: 0.49 - ETA: 2:22:26 - loss: 0.6956 - acc: 0. - ETA: 2:19:45 - loss: 0.6956 - acc - ETA: 2:14:36 - loss: 0.6957 - acc - ETA: 2:09:43 - loss: 0.6956 - acc: 0.49 - ETA: 2:08:31 - loss - ETA: 1:56:24 - loss: 0.6953 - acc - ETA: 1:52:22 - loss: 0.6954 - acc: 0. - ETA: 1:50:25 - loss: 0.6954 - acc - ETA: 1:46:39 - loss: 0.6955 - acc - ETA: 1:43:03 - loss: 0.6956 - acc - ETA: 1:39:36 - loss:  - ETA: 1:31:35 - loss: 0.6957 - acc: 0.49 - ETA: 1:30:49 -  - ETA: 1:21:37 - loss - ETA: 1:14:39 - loss: 0.6958 - acc:  - ETA: 1:12:52 - loss: 0. - ETA: 1:07:48 - loss: 0.69 - ETA: 1:03:36 - loss: 0.6959 - acc:  - ETA: 1:02:06 - loss: 0.6959 - acc - ETA: 1:00:09 - loss: 0.69 - ETA: 56:26 - loss: 0.6962 - a - ETA: 54:13 - loss: 0.69 - ETA: 2:31:29 - loss:  - ETA: 2:18 - ETA: 2:01 - ETA: 1:46 - ETA: 1:32:19 - loss: 0.6957 - acc:  - ETA: 1:29:52 - loss: 0.6957 - acc: 0.49 - ETA: 1:29:03 - loss - ETA: 1:40:19 - loss: 0.6958 - acc: 0.4962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.112412). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/500 [===================>..........] - ETA: 1:38:27 - loss: 0.6959 - acc: 0.4952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105278). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.102333). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/500 [========================>.....] - ETA: 42:21 - loss: 0.6954 - acc: 0.499677 ETA: 1:33:52 - lo - ETA: 1:23 - ETA: 1:10:25 - loss: 0.6956 - acc: 0. - ETA: 1:08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.168958). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/500 [========================>.....] - ETA: 41:43 - loss: 0.6954 - acc: 0.4996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.155008). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.134712). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/500 [========================>.....] - ETA: 40:27 - loss: 0.6954 - acc: 0.4994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.125492). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.123418). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/500 [========================>.....] - ETA: 39:50 - loss: 0.6954 - acc: 0.49 - ETA: 39:12 - loss: 0.6954 - acc: 0.4997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.114557). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/500 [========================>.....] - ETA: 37:58 - loss: 0.6954 - acc: 0.4993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.116438). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.104511). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 13554s 27s/step - loss: 0.6954 - acc: 0.4994 - val_loss: 0.6926 - val_acc: 0.5210TA: 33:44 - loss: 0.6954 - acc - ETA: 31:22 - loss:  - ETA: 25:38 - ETA: 4:36 - loss: 0.6953 - acc: 0.4 - ETA: 3:12 - loss: 0.6953 - ac\n",
      "Epoch 7/10\n",
      "144/500 [=======>......................] - ETA: 1:21:51 - loss: 0.6950 - acc: 0.5011: 46s - loss: 0.6929 - acc:  - ETA: 46s - loss: 0.6935 - acc: 0.51 - ETA: 46s - loss: 0.6933 - acc: 0.52 - ETA: 45s - loss: 0.6930 - - ETA: 45s - loss: 0.6935 - acc:  - ETA: 45s - loss: 0. - ETA: 44s - loss: 0.6945 - acc: 0. - ETA: 44s - loss: 0. - ETA: 2: - ETA"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.239725). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/500 [=======>......................] - ETA: 1:18:47 - loss: 0.6951 - acc: 0.5013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.225725). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.180011). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/500 [========>.....................] - ETA: 1:17:18 - loss: 0.6951 - acc: 0.5006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.117559). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101928). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/500 [=====================>........] - ETA: 11:19 - loss: 0.6947 - acc: 0.5015   ETA: 1:04:58 - loss: 0.6951 - acc: 0.50 - ETA: 1:04:23 - loss: 0.6951 - - ETA: 50:40 - loss:  - ETA: 46:40 - loss: 0.6948 - acc:  - ETA: 45:32 - loss: 0.6947 - acc: 0.50 - ETA: 45:10  - ETA: 40:20 - loss: 0.6946 - acc: 0.50 - ETA: 40:01 - loss: 0.6946 - acc: 0.50 - ETA: 39:42 - loss: 0.6945 - - ETA: 37:50 - loss:  - ETA: 34:56 - loss: 0.6947 - - ETA: 33:18 - loss: 0. - ETA: 31:00 - loss: 0.6945 - acc:  - ETA: 30:16 - loss: 0.6944 - ETA: 28:38 - loss: 0. - ETA: 26:38 - loss: 0.6946 - - ETA: 25:22 - loss: 0.6945 - acc: 0.50 - ETA: 25:10 - loss: 0.6945 - acc:  - ETA: 21:45 - loss: 0.69 - ETA: 20:19 - loss: 0.6945 - acc: 0.50 - ETA: 20:08 - loss: 0. - E - ETA: 15 - ETA: 13:1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.256259). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/500 [=====================>........] - ETA: 10:57 - loss: 0.6947 - acc: 0.50 - ETA: 10:50 - loss: 0.6947 - acc: 0.5018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.222084). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.165622). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385/500 [======================>.......] - ETA: 10:36 - loss: 0.6948 - acc: 0.5013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.132719). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/Users/satoutakumi/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.109679). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2143s 4s/step - loss: 0.6950 - acc: 0.4994 - val_loss: 0.6941 - val_acc: 0.5132TA: 5:36 - loss: 0.6947 - acc:  - ETA: 5:02 - loss: 0.6947 - acc: 0 - ETA: 4:34 - loss: 0.6946 -  - ETA: 3:36 - loss: 0.6947 - acc: 0.501 - ETA: 3:31 - loss: 0.6947 - acc: 0.5 - ETA: 3:16 - loss: 0.6947 - acc: 0.5 - ETA: 3:00 - loss: 0.6947 - acc - ETA: 2:21 - loss: 0.6947 - acc:  - ETA: 1:52 - loss: 0.6948 - acc: 0.5 - ETA: 1:38 - loss: 0.6948 - acc: 0. - ETA: 1:19 - loss: 0.6948 - acc: - ETA: 52s - loss\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 100s 199ms/step - loss: 0.6946 - acc: 0.4994 - val_loss: 0.6947 - val_acc: 0.4980 0.693 - ETA: 57s - loss:  - ETA - ETA: 47s - loss: 0.6944 - acc: 0.50 - E - ETA: 25s - loss: 0.6944 - acc: 0.50 - ETA: 24s - loss: 0.6944 - ETA: 13s - loss: 0.69 - ETA: 11s - loss: 0. - ETA: 9s - loss: 0.6946 - acc: 0.49 - ETA: 9s - loss: 0.6946 - acc: 0.4 - ETA: 8s - loss: 0.6946 - acc: 0.50 - ETA: 8s - loss: 0.6946 - acc: 0.500 - ETA: 7s - loss: 0.694 - ETA: 4s - loss: 0.6945 - acc: 0. - ETA: 3s - loss: 0.6945 - acc: 0.5 - ETA: 3s - loss: 0.6946 - acc: 0 - ETA: 2s - loss: 0.6946 - acc: 0.4 - ETA: 1s - loss: 0.6946 - acc: 0.4 - ETA: 0s - loss: 0.6946 - acc: 0\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.6945 - acc: 0.5028 - val_loss: 0.6939 - val_acc: 0.5078oss:  - ETA: 50s - loss - ETA:  - ETA: 50s - loss: 0.6933 - ETA: 49s - loss: 0.6933 - a - ETA: 48s - loss: 0.6933 - acc - ETA: 48s - loss: 0.6934 - acc: 0.51 - ETA: 48s - loss: 0.6935 - ETA: 47s - loss: 0.6929 - acc - ETA: 46s - loss: 0.6928 - acc: 0. - ETA: 46s - loss: 0.6929 - - ETA: 45s - loss:  - ETA: 45s - loss: 0.6932 - a - ETA - ETA: 40s - lo - ETA: 39s - loss: 0.6933 - acc: 0.51 - ETA: 39s - loss: 0.6934 - a - ETA: 38s  - ETA: 37s - loss: 0.6939 - acc - ETA: 36s - loss: 0.6941 - acc:  - ETA: 36s - loss: 0.6941 - ETA: 35s - loss: 0.6939 - - ETA: 34s - loss - ETA: 33s - loss: 0.6941 - - ETA: 32s - loss: 0.6941 - acc - ETA: 32s - loss: 0.6942 - acc: 0. - ETA: 32s - loss - ETA: 30s - loss: 0.6943 - acc:  - ETA: 30s - loss: 0.6944 - acc - ETA: 30s - loss: 0.6943 - acc - ETA: 29s - loss - ETA: 28s - loss: 0.6944 - - ETA: 27s - loss: 0.6943 - acc: 0. - ETA: 27s - loss: 0.6943 - ETA: 26s - loss: 0.6943 - acc:  - ETA: 26s - loss: 0.69 - ETA: 25s - loss: 0.6945 - acc: 0.50 - ETA: 25s - loss: 0.6945 - acc: 0. - ETA: 25s - loss: 0.6944 - acc: 0. - ETA: 25s - loss: 0.6945 - acc:  - ETA: 24s - loss: 0. - ETA: 23s - loss - ETA: 22s - loss: 0.6943 - a - ETA: 19s - loss: 0.6942 - acc - ETA: 19s - lo - ETA: 18s - loss: 0.6944 - a - ETA: 17s - loss: 0.69 - ETA: 16s - loss: 0.69 - ETA: 15s - loss: 0.6943 - acc: 0. - ETA: 15s - lo - ETA: 14s - loss: 0.6943 - acc: 0.50 - ETA: 14s - loss: 0.6943 - ETA: 7s - loss: 0.6944 - - ETA: 6s - loss: 0.6945 - acc: 0.502 - ETA: 6s - loss: 0.6945 - acc: 0 - ETA: 5s - loss: 0.6945 - acc: 0. - ETA: 5s - loss: 0.6944 - - ETA: 3s - loss: 0.6944 - acc:  - ETA: 3s - loss: 0.6944 - acc:  - ETA: 2s - loss: 0.6944 - acc: 0.5 - ETA: 2s - loss: 0.6944 - acc: - ETA: 1s - loss: 0.6944 - acc:  - ETA: 0s - loss: 0.6944 - acc: - ETA: 0s - loss: 0.6944 - acc: 0.502\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.6947 - acc: 0.5010 - val_loss: 0.6936 - val_acc: 0.5088 42s - loss: 0.6950 - a - ETA: 41s - loss: 0.6951 - acc:  - - ETA: 39s - loss: 0.6944 - acc: 0.50 - ETA: 39s - loss:  - ETA: 37s - loss:  - ETA: 36s - loss: 0.6947 - ETA: 36s - loss: 0. - ETA: 28 - ETA: 25 - ETA - ETA: 21s - loss: 0.69 - ETA: 20s - loss: 0.6946 - acc: 0.50 - ETA: 20s - loss: 0. - ETA: 8s - loss: 0.6946 - ETA: 6s - loss: 0.6947 - acc: - ETA: 5s - loss: 0.694 - - ETA: 0s - loss: 0.6947 - acc: 0.501\n"
=======
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
      "500/500 [==============================] - 60s 119ms/step - loss: 0.7049 - acc: 0.5006 - val_loss: 0.7013 - val_acc: 0.4971\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 52s 105ms/step - loss: 0.6988 - acc: 0.4953 - val_loss: 0.6998 - val_acc: 0.4980\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 0.6960 - acc: 0.5001 - val_loss: 0.6965 - val_acc: 0.4995\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 0.6959 - acc: 0.5003 - val_loss: 0.6955 - val_acc: 0.4985\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 0.6960 - acc: 0.4949 - val_loss: 0.6964 - val_acc: 0.4893\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 0.6959 - acc: 0.4989 - val_loss: 0.6940 - val_acc: 0.4956\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 0.6955 - acc: 0.4951 - val_loss: 0.6972 - val_acc: 0.5117\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 0.6957 - acc: 0.4945 - val_loss: 0.6971 - val_acc: 0.4941\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 52s 105ms/step - loss: 0.6952 - acc: 0.4974 - val_loss: 0.6954 - val_acc: 0.5024\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 0.6957 - acc: 0.4970 - val_loss: 0.6959 - val_acc: 0.4966\n"
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
     ]
    }
   ],
   "source": [
    "# make a generator out of the data\n",
    "def siam_gen(in_groups, batch_size = 32):\n",
    "    while True:\n",
    "        pv_a, pv_b, pv_sim = gen_random_batch(train_groups, batch_size//2)\n",
    "        yield [pv_a, pv_b], pv_sim\n",
    "        \n",
    "\n",
    "valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024)\n",
    "loss_history = model.fit_generator(siam_gen(train_groups), \n",
    "                                                            steps_per_epoch = 500,\n",
    "                                                            validation_data=([valid_a, valid_b], valid_sim),\n",
    "                                                            epochs = 10,\n",
    "                                                            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.6.3"
=======
   "version": "3.6.4"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "version": "3.6.4"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
=======
   "version": "3.6.4"
>>>>>>> 1c7d0f143dc936c9b28e0e156f720b0fce55eafd
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
